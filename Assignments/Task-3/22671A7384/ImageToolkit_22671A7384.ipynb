{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7bfb1b",
   "metadata": {},
   "source": [
    "\n",
    "# üñºÔ∏è OpenCV Image Processor (Streamlit) ‚Äî Step‚Äëby‚ÄëStep Notebook\n",
    "\n",
    "**Goal:** This notebook explains the provided Streamlit app, which demonstrates **fundamental Image Processing operations** using **OpenCV**, and shows how each piece works with compact, runnable examples.\n",
    "\n",
    "You will learn:\n",
    "\n",
    "- How the GUI is structured in Streamlit (sidebar controls, session state, display area).\n",
    "- What each image operation does (color conversions, geometric transforms, filtering, enhancement, edge detection, compression).\n",
    "- How the real-time webcam section is wired.\n",
    "- How to run, extend, and debug the app.\n",
    "\n",
    "> This notebook is meant as a **teaching companion** for your Streamlit GUI. It includes runnable demo snippets on synthetic images so you can see effects without relying on external files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34de479",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Prerequisites & Setup\n",
    "\n",
    "Install dependencies (in your terminal/command prompt):\n",
    "\n",
    "```bash\n",
    "pip install streamlit opencv-python numpy pillow matplotlib\n",
    "```\n",
    "\n",
    "Run the app (after you download/write `app.py`):\n",
    "\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "> **Tip:** If you are on Windows and your webcam doesn't start, close any other app that might be using the camera, and try launching Streamlit from a normal terminal (not inside some IDE). If it still fails, try changing the camera index from `0` ‚Üí `1` in `cv2.VideoCapture(0)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22fc08e",
   "metadata": {},
   "source": [
    "\n",
    "## üß± App Architecture (High Level)\n",
    "\n",
    "- **`ImageProcessor` class**: All core image operations live here (color conversions, transforms, filtering, enhancement, edges).\n",
    "- **Streamlit UI**:\n",
    "  - **Sidebar**: Upload image, pick operations, tweak sliders, save output.\n",
    "  - **Main area**: Side‚Äëby‚Äëside **Original** vs **Processed** + a status bar.\n",
    "  - **Webcam Bonus**: Optional real‚Äëtime processing preview.\n",
    "- **State**: `st.session_state.operation` and `st.session_state.processor` remember the current operation and images.\n",
    "\n",
    "**Flow:** Upload ‚Üí choose operation ‚Üí app calls the corresponding `ImageProcessor` method ‚Üí result appears on the right.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3541b269",
   "metadata": {},
   "source": [
    "\n",
    "## üìé Full App Code (Reference)\n",
    "\n",
    "For convenience, the full Streamlit app is embedded below (with small label fixes like `RGB` instead of `RGBO`). You can write it out as `app.py` from the notebook if you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f3230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optionally write the app code to a local file for you to run:\n",
    "app_path = \"/mnt/data/app.py\"\n",
    "with open(app_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write('''\n",
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import time\n",
    "\n",
    "# Set page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"OpenCV Image Processor\",\n",
    "    page_icon=\"üñºÔ∏è\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Custom CSS for better styling\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main-header {\n",
    "        font-size: 2.5rem;\n",
    "        font-weight: 600;\n",
    "        color: #1f2937;\n",
    "        text-align: center;\n",
    "        margin-bottom: 2rem;\n",
    "    }\n",
    "    .section-header {\n",
    "        font-size: 1.2rem;\n",
    "        font-weight: 600;\n",
    "        color: #374151;\n",
    "        margin-bottom: 1rem;\n",
    "        border-bottom: 2px solid #10b981;\n",
    "        padding-bottom: 0.5rem;\n",
    "    }\n",
    "    .image-container {\n",
    "        border: 2px solid #e5e7eb;\n",
    "        border-radius: 8px;\n",
    "        padding: 1rem;\n",
    "        margin: 1rem 0;\n",
    "    }\n",
    "    .stButton > button {\n",
    "        width: 100%;\n",
    "        margin: 0.25rem 0;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self):\n",
    "        self.original_image = None\n",
    "        self.processed_image = None\n",
    "\n",
    "    def load_image(self, uploaded_file):\n",
    "        \"\"\"Load and convert uploaded image to OpenCV format with error handling\"\"\"\n",
    "        if uploaded_file is not None:\n",
    "            try:\n",
    "                pil_image = Image.open(uploaded_file)\n",
    "                if pil_image.mode != 'RGB':\n",
    "                    pil_image = pil_image.convert('RGB')\n",
    "                opencv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "                self.original_image = opencv_image\n",
    "                return opencv_image\n",
    "            except Exception as e:\n",
    "                st.error(f\"‚ùå Failed to load image: {e}\")\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "    def convert_for_display(self, image):\n",
    "        \"\"\"Convert OpenCV image (BGR) to format suitable for Streamlit display\"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "\n",
    "    # Color Conversion Operations\n",
    "    def rgb_to_grayscale(self, image):\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    def rgb_to_hsv(self, image):\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        return hsv\n",
    "\n",
    "    def rgb_to_sepia(self, image):\n",
    "        sepia_filter = np.array([[0.272, 0.534, 0.131],\n",
    "                                [0.349, 0.686, 0.168],\n",
    "                                [0.393, 0.769, 0.189]])\n",
    "        sepia_img = cv2.transform(image, sepia_filter)\n",
    "        return np.clip(sepia_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    def invert_colors(self, image):\n",
    "        return cv2.bitwise_not(image)\n",
    "\n",
    "    # Geometric Transformations\n",
    "    def rotate_image(self, image, angle):\n",
    "        height, width = image.shape[:2]\n",
    "        center = (width // 2, height // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image, rotation_matrix, (width, height), \n",
    "                                borderValue=(255, 255, 255))\n",
    "        return rotated\n",
    "\n",
    "    def scale_image(self, image, scale_factor):\n",
    "        height, width = image.shape[:2]\n",
    "        new_width = int(width * scale_factor)\n",
    "        new_height = int(height * scale_factor)\n",
    "        scaled = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "        canvas = np.full_like(image, 255)\n",
    "        y_offset = max(0, (height - new_height) // 2)\n",
    "        x_offset = max(0, (width - new_width) // 2)\n",
    "        if new_height <= height and new_width <= width:\n",
    "            canvas[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = scaled\n",
    "        else:\n",
    "            crop_y = max(0, (new_height - height) // 2)\n",
    "            crop_x = max(0, (new_width - width) // 2)\n",
    "            canvas = scaled[crop_y:crop_y+height, crop_x:crop_x+width]\n",
    "        return canvas\n",
    "\n",
    "    def translate_image(self, image, tx, ty):\n",
    "        height, width = image.shape[:2]\n",
    "        translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "        translated = cv2.warpAffine(image, translation_matrix, (width, height),\n",
    "                                   borderValue=(255, 255, 255))\n",
    "        return translated\n",
    "\n",
    "    def flip_image(self, image, horizontal=False, vertical=False):\n",
    "        if horizontal and vertical:\n",
    "            return cv2.flip(image, -1)\n",
    "        elif horizontal:\n",
    "            return cv2.flip(image, 1)\n",
    "        elif vertical:\n",
    "            return cv2.flip(image, 0)\n",
    "        return image\n",
    "\n",
    "    # Filtering Operations\n",
    "    def gaussian_blur(self, image, kernel_size):\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    def sharpen_image(self, image, strength=1.0):\n",
    "        kernel = np.array([[0, -strength, 0],\n",
    "                          [-strength, 1 + 4*strength, -strength],\n",
    "                          [0, -strength, 0]], dtype=np.float32)\n",
    "        sharpened = cv2.filter2D(image, -1, kernel)\n",
    "        return np.clip(sharpened, 0, 255).astype(np.uint8)\n",
    "\n",
    "    def emboss_effect(self, image):\n",
    "        kernel = np.array([[-2, -1, 0],\n",
    "                          [-1, 1, 1],\n",
    "                          [0, 1, 2]], dtype=np.float32)\n",
    "        embossed = cv2.filter2D(image, -1, kernel)\n",
    "        return np.clip(embossed + 128, 0, 255).astype(np.uint8)\n",
    "\n",
    "    def edge_detection(self, image):\n",
    "        kernel = np.array([[-1, -1, -1],\n",
    "                          [-1, 8, -1],\n",
    "                          [-1, -1, -1]], dtype=np.float32)\n",
    "        edges = cv2.filter2D(image, -1, kernel)\n",
    "        return np.clip(edges, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Enhancement Operations\n",
    "    def histogram_equalization(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "            yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])\n",
    "            return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
    "        else:\n",
    "            return cv2.equalizeHist(image)\n",
    "\n",
    "    def contrast_stretch(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            stretched = np.zeros_like(image)\n",
    "            for i in range(3):\n",
    "                channel = image[:, :, i]\n",
    "                min_val, max_val = np.min(channel), np.max(channel)\n",
    "                if max_val > min_val:\n",
    "                    stretched[:, :, i] = ((channel - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
    "                else:\n",
    "                    stretched[:, :, i] = channel\n",
    "            return stretched\n",
    "        else:\n",
    "            min_val, max_val = np.min(image), np.max(image)\n",
    "            if max_val > min_val:\n",
    "                return ((image - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
    "            return image\n",
    "\n",
    "    def adjust_brightness(self, image, brightness):\n",
    "        adjusted = cv2.add(image, np.ones(image.shape, dtype=np.uint8) * brightness)\n",
    "        return np.clip(adjusted, 0, 255).astype(np.uint8)\n",
    "\n",
    "    def gamma_correction(self, image, gamma):\n",
    "        gamma_corrected = np.power(image / 255.0, gamma) * 255.0\n",
    "        return np.clip(gamma_corrected, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Edge Detection Operations\n",
    "    def sobel_edge_detection(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        return np.clip(sobel_combined, 0, 255).astype(np.uint8)\n",
    "\n",
    "    def canny_edge_detection(self, image, low_threshold=50, high_threshold=150):\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "        return edges\n",
    "\n",
    "    def laplacian_edge_detection(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        return np.clip(np.absolute(laplacian), 0, 255).astype(np.uint8)\n",
    "\n",
    "    def prewitt_edge_detection(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        kernel_x = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=np.float32)\n",
    "        kernel_y = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]], dtype=np.float32)\n",
    "        prewitt_x = cv2.filter2D(gray, cv2.CV_64F, kernel_x)\n",
    "        prewitt_y = cv2.filter2D(gray, cv2.CV_64F, kernel_y)\n",
    "        prewitt_combined = np.sqrt(prewitt_x**2 + prewitt_y**2)\n",
    "        return np.clip(prewitt_combined, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.markdown('<h1 class=\"main-header\">üñºÔ∏è OpenCV Image Processor</h1>', unsafe_allow_html=True)\n",
    "\n",
    "    # Initialize session state\n",
    "    if 'processor' not in st.session_state:\n",
    "        st.session_state.processor = ImageProcessor()\n",
    "    if 'operation' not in st.session_state:\n",
    "        st.session_state.operation = None\n",
    "\n",
    "    processor = st.session_state.processor\n",
    "\n",
    "    # Sidebar for controls\n",
    "    with st.sidebar:\n",
    "        st.markdown('<div class=\"section-header\">üìÅ Image Upload</div>', unsafe_allow_html=True)\n",
    "        uploaded_file = st.file_uploader(\"Choose an image file\", type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'])\n",
    "\n",
    "        if uploaded_file is not None:\n",
    "            original_image = processor.load_image(uploaded_file)\n",
    "            if original_image is not None:\n",
    "                st.success(f\"‚úÖ Image loaded: {uploaded_file.name}\")\n",
    "                height, width = original_image.shape[:2]\n",
    "                st.info(f\"üìè Dimensions: {width} √ó {height} pixels\")\n",
    "\n",
    "                # Color Conversions\n",
    "                st.markdown('<div class=\"section-header\">üé® Color Conversions</div>', unsafe_allow_html=True)\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    if st.button(\"RGB to Grayscale\"):\n",
    "                        st.session_state.operation = \"Grayscale\"\n",
    "                        processor.processed_image = processor.rgb_to_grayscale(original_image)\n",
    "                    if st.button(\"RGB to Sepia\"):\n",
    "                        st.session_state.operation = \"Sepia\"\n",
    "                        processor.processed_image = processor.rgb_to_sepia(original_image)\n",
    "                with col2:\n",
    "                    if st.button(\"RGB to HSV\"):\n",
    "                        st.session_state.operation = \"HSV\"\n",
    "                        processor.processed_image = processor.rgb_to_hsv(original_image)\n",
    "                    if st.button(\"Invert Colors\"):\n",
    "                        st.session_state.operation = \"Invert\"\n",
    "                        processor.processed_image = processor.invert_colors(original_image)\n",
    "\n",
    "                # Geometric Transformations\n",
    "                st.markdown('<div class=\"section-header\">üîÑ Geometric Transformations</div>', unsafe_allow_html=True)\n",
    "                st.subheader(\"üîÑ Rotation\")\n",
    "                rotation_angle = st.slider(\"Rotation Angle\", -180, 180, 0, key=\"rotation\")\n",
    "                if st.button(\"Apply Rotation\"):\n",
    "                    st.session_state.operation = f\"Rotate {rotation_angle}¬∞\"\n",
    "                    processor.processed_image = processor.rotate_image(original_image, rotation_angle)\n",
    "\n",
    "                st.subheader(\"üìè Scaling\")\n",
    "                scale_factor = st.slider(\"Scale Factor\", 0.1, 3.0, 1.0, 0.1, key=\"scale\")\n",
    "                if st.button(\"Apply Scaling\"):\n",
    "                    st.session_state.operation = f\"Scale {scale_factor}x\"\n",
    "                    processor.processed_image = processor.scale_image(original_image, scale_factor)\n",
    "\n",
    "                st.subheader(\"‚ÜîÔ∏è Translation\")\n",
    "                tx = st.slider(\"Translate X\", -100, 100, 0, key=\"tx\")\n",
    "                ty = st.slider(\"Translate Y\", -100, 100, 0, key=\"ty\")\n",
    "                if st.button(\"Apply Translation\"):\n",
    "                    st.session_state.operation = f\"Translate ({tx}, {ty})\"\n",
    "                    processor.processed_image = processor.translate_image(original_image, tx, ty)\n",
    "\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    if st.button(\"Flip Horizontal\"):\n",
    "                        st.session_state.operation = \"Flip Horizontal\"\n",
    "                        processor.processed_image = processor.flip_image(original_image, horizontal=True)\n",
    "                with col2:\n",
    "                    if st.button(\"Flip Vertical\"):\n",
    "                        st.session_state.operation = \"Flip Vertical\"\n",
    "                        processor.processed_image = processor.flip_image(original_image, vertical=True)\n",
    "\n",
    "                # Filtering Operations\n",
    "                st.markdown('<div class=\"section-header\">üåü Filtering Operations</div>', unsafe_allow_html=True)\n",
    "                st.subheader(\"üå´Ô∏è Gaussian Blur\")\n",
    "                blur_strength = st.slider(\"Blur Strength\", 1, 31, 5, 2, key=\"blur\")\n",
    "                if st.button(\"Apply Gaussian Blur\"):\n",
    "                    st.session_state.operation = f\"Gaussian Blur {blur_strength}\"\n",
    "                    processor.processed_image = processor.gaussian_blur(original_image, blur_strength)\n",
    "\n",
    "                st.subheader(\"‚ú® Sharpen\")\n",
    "                sharpen_strength = st.slider(\"Sharpen Strength\", 0.1, 3.0, 1.0, 0.1, key=\"sharpen\")\n",
    "                if st.button(\"Apply Sharpening\"):\n",
    "                    st.session_state.operation = f\"Sharpen {sharpen_strength}\"\n",
    "                    processor.processed_image = processor.sharpen_image(original_image, sharpen_strength)\n",
    "\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    if st.button(\"Emboss Effect\"):\n",
    "                        st.session_state.operation = \"Emboss\"\n",
    "                        processor.processed_image = processor.emboss_effect(original_image)\n",
    "                with col2:\n",
    "                    if st.button(\"Edge Detection\"):\n",
    "                        st.session_state.operation = \"Edge Detection\"\n",
    "                        processor.processed_image = processor.edge_detection(original_image)\n",
    "\n",
    "                # Enhancement Operations\n",
    "                st.markdown('<div class=\"section-header\">‚ú® Enhancement Operations</div>', unsafe_allow_html=True)\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    if st.button(\"Histogram Equalization\"):\n",
    "                        st.session_state.operation = \"Histogram Equalization\"\n",
    "                        processor.processed_image = processor.histogram_equalization(original_image)\n",
    "                with col2:\n",
    "                    if st.button(\"Contrast Stretch\"):\n",
    "                        st.session_state.operation = \"Contrast Stretch\"\n",
    "                        processor.processed_image = processor.contrast_stretch(original_image)\n",
    "\n",
    "                st.subheader(\"üí° Brightness\")\n",
    "                brightness = st.slider(\"Brightness\", -100, 100, 0, key=\"brightness\")\n",
    "                if st.button(\"Apply Brightness\"):\n",
    "                    st.session_state.operation = f\"Brightness {brightness}\"\n",
    "                    processor.processed_image = processor.adjust_brightness(original_image, brightness)\n",
    "\n",
    "                st.subheader(\"üåà Gamma Correction\")\n",
    "                gamma = st.slider(\"Gamma\", 0.1, 3.0, 1.0, 0.1, key=\"gamma\")\n",
    "                if st.button(\"Apply Gamma Correction\"):\n",
    "                    st.session_state.operation = f\"Gamma {gamma}\"\n",
    "                    processor.processed_image = processor.gamma_correction(original_image, gamma)\n",
    "\n",
    "                # Edge Detection Operations\n",
    "                st.markdown('<div class=\"section-header\">üîç Edge Detection</div>', unsafe_allow_html=True)\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    if st.button(\"Sobel Edge Detection\"):\n",
    "                        st.session_state.operation = \"Sobel\"\n",
    "                        processor.processed_image = processor.sobel_edge_detection(original_image)\n",
    "                    if st.button(\"Laplacian Edge Detection\"):\n",
    "                        st.session_state.operation = \"Laplacian\"\n",
    "                        processor.processed_image = processor.laplacian_edge_detection(original_image)\n",
    "                with col2:\n",
    "                    if st.button(\"Prewitt Edge Detection\"):\n",
    "                        st.session_state.operation = \"Prewitt\"\n",
    "                        processor.processed_image = processor.prewitt_edge_detection(original_image)\n",
    "\n",
    "                st.subheader(\"üéØ Canny Edge Detection\")\n",
    "                canny_low = st.slider(\"Low Threshold\", 0, 255, 50, key=\"canny_low\")\n",
    "                canny_high = st.slider(\"High Threshold\", 0, 255, 150, key=\"canny_high\")\n",
    "                if st.button(\"Apply Canny Edge Detection\"):\n",
    "                    st.session_state.operation = f\"Canny ({canny_low}, {canny_high})\"\n",
    "                    processor.processed_image = processor.canny_edge_detection(original_image, canny_low, canny_high)\n",
    "\n",
    "                # Compression & Save\n",
    "                st.markdown('<div class=\"section-header\">üíæ Compression & Save</div>', unsafe_allow_html=True)\n",
    "                format_comp = st.selectbox(\"Save Format\", [\"PNG\", \"JPG\", \"BMP\"], key=\"save_format\")\n",
    "                if st.button(\"üíæ Save Processed Image\"):\n",
    "                    if processor.processed_image is not None:\n",
    "                        if len(processor.processed_image.shape) == 3:\n",
    "                            pil_image = Image.fromarray(processor.convert_for_display(processor.processed_image))\n",
    "                        else:\n",
    "                            pil_image = Image.fromarray(processor.processed_image)\n",
    "\n",
    "                        buf = io.BytesIO()\n",
    "                        if format_comp == \"JPG\":\n",
    "                            pil_image = pil_image.convert(\"RGB\")\n",
    "                            pil_image.save(buf, format='JPEG', quality=95)\n",
    "                        else:\n",
    "                            pil_image.save(buf, format=format_comp)\n",
    "                        buf.seek(0)\n",
    "                        file_size_kb = len(buf.getvalue()) / 1024\n",
    "                        st.success(f\"‚úÖ Saved as {format_comp} - Size: {file_size_kb:.2f} KB\")\n",
    "                        st.download_button(\n",
    "                            label=f\"‚¨áÔ∏è Download {format_comp}\",\n",
    "                            data=buf.getvalue(),\n",
    "                            file_name=f\"processed_{uploaded_file.name.split('.')[0]}.{format_comp.lower()}\",\n",
    "                            mime=f\"image/{'jpeg' if format_comp == 'JPG' else format_comp.lower()}\"\n",
    "                        )\n",
    "\n",
    "                st.markdown(\"---\")\n",
    "                if st.button(\"üîÑ Reset to Original\"):\n",
    "                    processor.processed_image = None\n",
    "                    st.session_state.operation = None\n",
    "\n",
    "    # üé• Real-time Webcam (Bonus)\n",
    "    st.sidebar.markdown('<div class=\"section-header\">üé• Real-time Webcam (Bonus)</div>', unsafe_allow_html=True)\n",
    "    run_webcam = st.sidebar.checkbox(\"‚ñ∂Ô∏è Start Webcam\", key=\"webcam_toggle\")\n",
    "    FRAME_WINDOW = st.empty()\n",
    "\n",
    "    if run_webcam:\n",
    "        cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "        if not cap.isOpened():\n",
    "            st.error(\"‚ùå Cannot access webcam. Check permissions or close other apps.\")\n",
    "            st.stop()\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        st.success(\"‚úÖ Webcam initialized. Press 'Stop' to end.\")\n",
    "\n",
    "        try:\n",
    "            while run_webcam:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret or frame is None or frame.size == 0:\n",
    "                    st.warning(\"‚ö†Ô∏è Received empty frame. Skipping...\")\n",
    "                    time.sleep(0.1)\n",
    "                    continue\n",
    "\n",
    "                op = st.session_state.operation\n",
    "                if op:\n",
    "                    try:\n",
    "                        if \"Grayscale\" in op:\n",
    "                            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                            frame = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "                        elif \"Gaussian Blur\" in op:\n",
    "                            ksize = 5\n",
    "                            try:\n",
    "                                ksize = int(op.split()[-1])\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                            if ksize % 2 == 0:\n",
    "                                ksize += 1\n",
    "                            frame = cv2.GaussianBlur(frame, (ksize, ksize), 0)\n",
    "                        elif \"Rotate\" in op:\n",
    "                            try:\n",
    "                                angle = int(op.split()[1].replace(\"¬∞\",\"\"))\n",
    "                            except Exception:\n",
    "                                angle = 0\n",
    "                            h, w = frame.shape[:2]\n",
    "                            center = (w // 2, h // 2)\n",
    "                            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "                            frame = cv2.warpAffine(frame, M, (w, h))\n",
    "                        elif \"Scale\" in op:\n",
    "                            try:\n",
    "                                scale = float(op.split()[1].replace(\"x\",\"\"))\n",
    "                            except Exception:\n",
    "                                scale = 1.0\n",
    "                            h, w = frame.shape[:2]\n",
    "                            new_w, new_h = int(w * scale), int(h * scale)\n",
    "                            frame = cv2.resize(frame, (new_w, new_h))\n",
    "                            canvas = np.full((h, w, 3), 255, dtype=np.uint8)\n",
    "                            y1 = max(0, (h - new_h) // 2)\n",
    "                            x1 = max(0, (w - new_w) // 2)\n",
    "                            y2 = min(h, y1 + new_h)\n",
    "                            x2 = min(w, x1 + new_w)\n",
    "                            frame_cropped = frame[0:y2-y1, 0:x2-x1]\n",
    "                            canvas[y1:y2, x1:x2] = frame_cropped\n",
    "                            frame = canvas\n",
    "                    except Exception as e:\n",
    "                        st.warning(f\"‚ö†Ô∏è Failed to apply {op}: {e}\")\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                FRAME_WINDOW.image(frame_rgb, channels=\"RGB\", use_container_width=True)\n",
    "                time.sleep(0.03)\n",
    "                run_webcam = st.session_state.webcam_toggle\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"üõë Critical error: {e}\")\n",
    "        finally:\n",
    "            cap.release()\n",
    "            st.info(\"üìπ Webcam released. Ready for next use.\")\n",
    "\n",
    "    # Main display area\n",
    "    if 'processor' in st.session_state and st.session_state.processor.original_image is not None:\n",
    "        processor = st.session_state.processor\n",
    "        uploaded_file_placeholder = st.session_state.get(\"uploaded_file_name\", \"uploaded_file\")\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        with col1:\n",
    "            st.markdown('<div class=\"section-header\">üì∑ Original Image</div>', unsafe_allow_html=True)\n",
    "            st.image(processor.convert_for_display(processor.original_image), \n",
    "                     caption=f\"Original\", use_container_width=True)\n",
    "\n",
    "        with col2:\n",
    "            st.markdown('<div class=\"section-header\">‚öôÔ∏è Processed Image</div>', unsafe_allow_html=True)\n",
    "            if processor.processed_image is not None:\n",
    "                display_image = processor.convert_for_display(processor.processed_image)\n",
    "                st.image(display_image, caption=f\"Applied: {st.session_state.operation}\", use_container_width=True)\n",
    "            else:\n",
    "                st.info(\"üëà Select an operation from the sidebar to see the processed result\")\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        cols = st.columns(4)\n",
    "        cols[0].metric(\"Operation\", st.session_state.operation if st.session_state.operation else \"None\")\n",
    "        if processor.processed_image is not None:\n",
    "            h, w = processor.processed_image.shape[:2]\n",
    "            c = 3 if len(processor.processed_image.shape) == 3 else 1\n",
    "            cols[1].metric(\"Dimensions\", f\"{w}√ó{h}√ó{c}\")\n",
    "        else:\n",
    "            cols[1].metric(\"Dimensions\", \"‚Äî\")\n",
    "        # File format/size only available for uploads; here we omit for simplicity.\n",
    "        cols[2].metric(\"Format\", \"‚Äî\")\n",
    "        cols[3].metric(\"File Size\", \"‚Äî\")\n",
    "\n",
    "    else:\n",
    "        st.info(\"üëÜ Please upload an image file to get started\")\n",
    "        st.markdown(\"### üéØ Available Operations:\")\n",
    "        operations = {\n",
    "            \"üé® Color Conversions\": [\"RGB to Grayscale\", \"RGB to HSV\", \"RGB to Sepia\", \"Invert Colors\"],\n",
    "            \"üîÑ Geometric Transformations\": [\"Rotation\", \"Scaling\", \"Translation\", \"Flip Horizontal/Vertical\"],\n",
    "            \"üåü Filtering Operations\": [\"Gaussian Blur\", \"Sharpen\", \"Emboss\", \"Edge Detection\"],\n",
    "            \"‚ú® Enhancement Operations\": [\"Histogram Equalization\", \"Contrast Stretch\", \"Brightness\", \"Gamma Correction\"],\n",
    "            \"üîç Edge Detection\": [\"Sobel\", \"Canny\", \"Laplacian\", \"Prewitt\"],\n",
    "            \"üíæ Compression\": [\"Save as JPG/PNG/BMP with size comparison\"],\n",
    "            \"üé• Bonus\": [\"Real-time Webcam Processing\"]\n",
    "        }\n",
    "        for category, ops in operations.items():\n",
    "            st.markdown(f\"**{category}**\")\n",
    "            st.write(\" ‚Ä¢ \".join(ops))\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.caption(\"üìò Module 1 ‚Äì Image Processing Fundamentals & Computer Vision\")\n",
    "    st.caption(\"üõ†Ô∏è Built with Streamlit + OpenCV | üü¢ Beginner ‚Üí üü† Intermediate ‚Üí üî¥ Advanced\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "''')\n",
    "app_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc2f9a5",
   "metadata": {},
   "source": [
    "\n",
    "## üß™ Quick Demo Setup (Synthetic Image)\n",
    "\n",
    "To keep this notebook self-contained, we'll create a synthetic test image (gradient + shapes). We'll reuse it across demos below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d2fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_test_image(h=256, w=256):\n",
    "    # Gradient background\n",
    "    x = np.linspace(0, 255, w, dtype=np.uint8)\n",
    "    grad = np.tile(x, (h,1))\n",
    "    img = np.dstack([grad, np.flipud(grad), np.roll(grad, 64, axis=1)])  # 3-channel RGB-like\n",
    "\n",
    "    # Draw shapes\n",
    "    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.circle(img_bgr, (w//4, h//3), 30, (255, 0, 0), -1)      # Blue circle (BGR)\n",
    "    cv2.rectangle(img_bgr, (140, 150), (220, 220), (0, 255, 0), 3)  # Green rectangle\n",
    "    cv2.putText(img_bgr, \"OpenCV\", (60, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
    "    return img_bgr\n",
    "\n",
    "test_img = make_test_image()\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Synthetic Test Image (BGR shown as RGB)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb771125",
   "metadata": {},
   "source": [
    "\n",
    "## üé® Color Conversions (BGR ‚Üî Gray/HSV/Sepia/Invert)\n",
    "\n",
    "Your app provides these conversions:\n",
    "\n",
    "- **BGR ‚Üí Grayscale**\n",
    "- **BGR ‚Üí HSV**\n",
    "- **Sepia (matrix transform)**\n",
    "- **Invert**\n",
    "\n",
    "Below is how each works and a runnable demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BGR ‚Üí Gray\n",
    "gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# BGR ‚Üí HSV\n",
    "hsv = cv2.cvtColor(test_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Sepia via 3x3 transform\n",
    "sepia_filter = np.array([[0.272, 0.534, 0.131],\n",
    "                         [0.349, 0.686, 0.168],\n",
    "                         [0.393, 0.769, 0.189]])\n",
    "sepia = cv2.transform(test_img, sepia_filter).clip(0,255).astype(np.uint8)\n",
    "\n",
    "# Invert\n",
    "inverted = cv2.bitwise_not(test_img)\n",
    "\n",
    "# Show (one plot per figure as requested)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for title, img in [\n",
    "    (\"Grayscale (visualized as RGB)\", cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)),\n",
    "    (\"HSV (visualized as RGB conversion)\", cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)),\n",
    "    (\"Sepia\", cv2.cvtColor(sepia, cv2.COLOR_BGR2RGB)),\n",
    "    (\"Invert\", cv2.cvtColor(inverted, cv2.COLOR_BGR2RGB))\n",
    "]:\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be641d1",
   "metadata": {},
   "source": [
    "\n",
    "## üîÑ Geometric Transformations\n",
    "\n",
    "The app implements:\n",
    "\n",
    "- **Rotation:** using `cv2.getRotationMatrix2D` + `cv2.warpAffine`\n",
    "- **Scaling:** using `cv2.resize` + smart padding/cropping to preserve canvas size\n",
    "- **Translation:** using an affine matrix `[[1, 0, tx], [0, 1, ty]]`\n",
    "- **Flips:** via `cv2.flip`\n",
    "\n",
    "Demo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ffb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h, w = test_img.shape[:2]\n",
    "\n",
    "# Rotation\n",
    "M_rot = cv2.getRotationMatrix2D((w//2, h//2), 30, 1.0)\n",
    "rotated = cv2.warpAffine(test_img, M_rot, (w, h), borderValue=(255,255,255))\n",
    "\n",
    "# Scaling (0.6x) with simple resize (no canvas pad here)\n",
    "scaled = cv2.resize(test_img, (int(w*0.6), int(h*0.6)))\n",
    "\n",
    "# Translation (+20, -15)\n",
    "M_trans = np.float32([[1, 0, 20], [0, 1, -15]])\n",
    "translated = cv2.warpAffine(test_img, M_trans, (w, h), borderValue=(255,255,255))\n",
    "\n",
    "# Flips\n",
    "flip_h = cv2.flip(test_img, 1)\n",
    "flip_v = cv2.flip(test_img, 0)\n",
    "flip_hv = cv2.flip(test_img, -1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for title, img in [\n",
    "    (\"Rotated +30¬∞\", rotated),\n",
    "    (\"Scaled 0.6x (no canvas)\", cv2.cvtColor(scaled, cv2.COLOR_BGR2RGB)),\n",
    "    (\"Translated (+20, -15)\", translated),\n",
    "    (\"Flip Horizontal\", flip_h),\n",
    "    (\"Flip Vertical\", flip_v),\n",
    "    (\"Flip Both\", flip_hv)\n",
    "]:\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde6a2d",
   "metadata": {},
   "source": [
    "\n",
    "## üåü Filtering\n",
    "\n",
    "- **Gaussian Blur:** low-pass smoothing; kernel size must be odd.\n",
    "- **Sharpen:** custom 3√ó3 kernel emphasizing center pixel while subtracting neighbors.\n",
    "- **Emboss:** directional gradient-like kernel + bias (shift by 128) to keep values visible.\n",
    "- **Simple Edge (Laplacian-like kernel):** emphasizes edges by subtracting neighbors.\n",
    "\n",
    "Demo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gaussian blur (ksize must be odd)\n",
    "blur = cv2.GaussianBlur(test_img, (9, 9), 0)\n",
    "\n",
    "# Sharpen\n",
    "strength = 1.2\n",
    "kernel_sharp = np.array([[0, -strength, 0],\n",
    "                         [-strength, 1 + 4*strength, -strength],\n",
    "                         [0, -strength, 0]], dtype=np.float32)\n",
    "sharp = cv2.filter2D(test_img, -1, kernel_sharp).clip(0,255).astype(np.uint8)\n",
    "\n",
    "# Emboss\n",
    "kernel_emb = np.array([[-2, -1, 0],\n",
    "                       [-1, 1, 1],\n",
    "                       [0, 1, 2]], dtype=np.float32)\n",
    "emb = cv2.filter2D(test_img, -1, kernel_emb)\n",
    "emb = np.clip(emb + 128, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Edge-ish 3x3\n",
    "kernel_edge = np.array([[-1, -1, -1],\n",
    "                        [-1, 8, -1],\n",
    "                        [-1, -1, -1]], dtype=np.float32)\n",
    "edgeish = cv2.filter2D(test_img, -1, kernel_edge).clip(0,255).astype(np.uint8)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for title, img in [\n",
    "    (\"Gaussian Blur (9x9)\", blur),\n",
    "    (\"Sharpen (strength=1.2)\", sharp),\n",
    "    (\"Emboss\", emb),\n",
    "    (\"Edge-ish (3x3)\", edgeish),\n",
    "]:\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732481f",
   "metadata": {},
   "source": [
    "\n",
    "## ‚ú® Enhancement\n",
    "\n",
    "- **Histogram Equalization (Y channel in YUV):** Increases contrast on luminance only.\n",
    "- **Contrast Stretching:** Linear scaling channel-wise from min‚Üímax to 0‚Üí255.\n",
    "- **Brightness:** Adds a constant to each pixel (clipped to [0,255]).\n",
    "- **Gamma Correction:** Nonlinear mapping: `output = (input/255)^gamma * 255`.\n",
    "\n",
    "Demo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21242131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histogram Equalization on Y channel\n",
    "yuv = cv2.cvtColor(test_img, cv2.COLOR_BGR2YUV)\n",
    "yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])\n",
    "eq = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "# Contrast Stretch per channel\n",
    "cs = np.zeros_like(test_img)\n",
    "for i in range(3):\n",
    "    ch = test_img[:,:,i]\n",
    "    mn, mx = ch.min(), ch.max()\n",
    "    if mx > mn:\n",
    "        cs[:,:,i] = ((ch - mn) / (mx - mn) * 255).astype(np.uint8)\n",
    "    else:\n",
    "        cs[:,:,i] = ch\n",
    "\n",
    "# Brightness (+40)\n",
    "bright = cv2.add(test_img, np.ones(test_img.shape, dtype=np.uint8) * 40).clip(0,255).astype(np.uint8)\n",
    "\n",
    "# Gamma (0.5 and 2.0)\n",
    "gamma05 = (np.power(test_img/255.0, 0.5) * 255).clip(0,255).astype(np.uint8)\n",
    "gamma20 = (np.power(test_img/255.0, 2.0) * 255).clip(0,255).astype(np.uint8)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for title, img in [\n",
    "    (\"Hist. Equalization (Y channel)\", eq),\n",
    "    (\"Contrast Stretch\", cs),\n",
    "    (\"Brightness +40\", bright),\n",
    "    (\"Gamma 0.5 (brighter mids)\", gamma05),\n",
    "    (\"Gamma 2.0 (darker mids)\", gamma20),\n",
    "]:\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a9cdec",
   "metadata": {},
   "source": [
    "\n",
    "## üîç Edge Detection\n",
    "\n",
    "- **Sobel:** first derivative in X/Y directions; we combine magnitudes.\n",
    "- **Canny:** multi-stage edge detector with hysteresis thresholds.\n",
    "- **Laplacian:** second derivative highlighting rapid intensity changes.\n",
    "- **Prewitt:** similar to Sobel using fixed 3√ó3 kernels.\n",
    "\n",
    "Demo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare grayscale\n",
    "gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Sobel\n",
    "sx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "sobel = np.sqrt(sx**2 + sy**2)\n",
    "sobel = np.clip(sobel, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Canny\n",
    "canny = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "# Laplacian\n",
    "lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "lap = np.clip(np.abs(lap), 0, 255).astype(np.uint8)\n",
    "\n",
    "# Prewitt\n",
    "kx = np.array([[-1,0,1],[-1,0,1],[-1,0,1]], dtype=np.float32)\n",
    "ky = np.array([[-1,-1,-1],[0,0,0],[1,1,1]], dtype=np.float32)\n",
    "px = cv2.filter2D(gray, cv2.CV_64F, kx)\n",
    "py = cv2.filter2D(gray, cv2.CV_64F, ky)\n",
    "prewitt = np.sqrt(px**2 + py**2)\n",
    "prewitt = np.clip(prewitt, 0, 255).astype(np.uint8)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for title, img in [\n",
    "    (\"Sobel magnitude\", cv2.cvtColor(sobel, cv2.COLOR_GRAY2BGR)),\n",
    "    (\"Canny (50,150)\", cv2.cvtColor(canny, cv2.COLOR_GRAY2BGR)),\n",
    "    (\"Laplacian |¬∑|\", cv2.cvtColor(lap, cv2.COLOR_GRAY2BGR)),\n",
    "    (\"Prewitt magnitude\", cv2.cvtColor(prewitt, cv2.COLOR_GRAY2BGR)),\n",
    "]:\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf3a4d6",
   "metadata": {},
   "source": [
    "\n",
    "## üíæ Compression & Saving\n",
    "\n",
    "In the app, users can save processed images as **PNG / JPG / BMP** and see the approximate size.\n",
    "\n",
    "Below is an example of writing the test image to different formats from Python. (Paths will point to your notebook's `/mnt/data` folder.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301de937",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import io, os\n",
    "\n",
    "# Convert BGR ‚Üí RGB for PIL\n",
    "rgb = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "pil = Image.fromarray(rgb)\n",
    "\n",
    "paths = []\n",
    "# PNG\n",
    "buf_png = io.BytesIO()\n",
    "pil.save(buf_png, format=\"PNG\")\n",
    "paths.append((\"/mnt/data/test_img.png\", buf_png))\n",
    "\n",
    "# JPG (quality=95)\n",
    "buf_jpg = io.BytesIO()\n",
    "pil.convert(\"RGB\").save(buf_jpg, format=\"JPEG\", quality=95)\n",
    "paths.append((\"/mnt/data/test_img.jpg\", buf_jpg))\n",
    "\n",
    "# BMP\n",
    "buf_bmp = io.BytesIO()\n",
    "pil.save(buf_bmp, format=\"BMP\")\n",
    "paths.append((\"/mnt/data/test_img.bmp\", buf_bmp))\n",
    "\n",
    "for path, buffer in paths:\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(buffer.getvalue())\n",
    "\n",
    "[size for size in [(p, os.path.getsize(p)/1024) for p,_ in paths]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0198c",
   "metadata": {},
   "source": [
    "\n",
    "## üß† Streamlit Wiring & Session State\n",
    "\n",
    "Key patterns used by the app:\n",
    "\n",
    "- **Session State:**\n",
    "  - `st.session_state.processor` holds the `ImageProcessor` instance.\n",
    "  - `st.session_state.operation` stores the last applied operation name (also used by the webcam loop).\n",
    "- **Sidebar UI:** Buttons/Sliders set `operation` and call the corresponding method.\n",
    "- **Display:** We show original vs processed using `st.image`.\n",
    "- **Status Bar:** `st.metric` widgets reflect current operation/dimensions.\n",
    "- **Webcam:** `st.empty()` creates a live-updating placeholder; loop respects `webcam_toggle`.\n",
    "\n",
    "> **Common gotcha:** Make sure the webcam UI (checkbox/placeholder) is **outside** tight loops and that you re-read `st.session_state.webcam_toggle` to break the loop when unchecked.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea407ea8",
   "metadata": {},
   "source": [
    "\n",
    "## üé• Real-time Webcam Section (Explained)\n",
    "\n",
    "- Open the camera with `cv2.VideoCapture(0, cv2.CAP_DSHOW)` on Windows (or omit `CV_CAP_DSHOW` elsewhere).\n",
    "- After reading a frame, the code **optionally applies the current operation** (e.g., grayscale, blur, rotate, scale).\n",
    "- Convert **BGR ‚Üí RGB** before showing: `cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)`.\n",
    "- Use `FRAME_WINDOW.image(...)` to update the UI.\n",
    "- Sleep a tiny bit (‚âà0.03s) for ~30 FPS and to let Streamlit refresh.\n",
    "- Re-check the checkbox: `run_webcam = st.session_state.webcam_toggle` to exit gracefully.\n",
    "\n",
    "> If the webcam doesn't initialize, show an error and stop. Always `release()` the camera in `finally:` to avoid lock-ups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c7f02",
   "metadata": {},
   "source": [
    "\n",
    "## üß© Extensions You Can Add\n",
    "\n",
    "- **More color spaces:** YCbCr, LAB, etc.\n",
    "- **Morphology:** Dilation, erosion, opening, closing.\n",
    "- **Affine/Perspective:** 3/4-point warps with draggable landmarks.\n",
    "- **Split-View Compare:** Slider to reveal original vs processed in one canvas.\n",
    "- **Batch Mode:** Process multiple images and show a gallery.\n",
    "\n",
    "Each of these slots nicely into the `ImageProcessor` class + a new sidebar block.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed43bd",
   "metadata": {},
   "source": [
    "\n",
    "## üõ†Ô∏è Troubleshooting Notes\n",
    "\n",
    "- **\"RGBO\" labels in your original snippet:** likely a typo ‚Äî use **\"RGB\"**.\n",
    "- **Webcam busy/black screen:** Close other apps; try `VideoCapture(1)`; check browser permissions (if using Streamlit Cloud).\n",
    "- **Odd kernel sizes:** Gaussian blur kernels must be **odd**; the app ensures this.\n",
    "- **Color channel order:** OpenCV uses **BGR**, Streamlit expects **RGB**. Always convert before display/saving with PIL.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
